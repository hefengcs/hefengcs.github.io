<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Feng He (何峰)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://scholar.google.com.hk/citations?user=z_c2z70AAAAJ&hl=zh-CN">Google Scholar</a></div>
<div class="menu-item"><a href="https://github.com/hefengcs">GitHub</a></div>
<div class="menu-item"><a href="pub/wechat.png">Wechat</a></div>
<div class="menu-item"><a href="cv/cv-EN.pdf">CV</a></p></div>



</td>
<td id="layout-content">
<div id="toptitle">
<h1>Feng He (何峰) </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://hefengcs.github.io/"><img src="photos/bio.jpg" alt="alt text" width="178px" height="192px" /></a>&nbsp;</td>
<td align="left"><p>MPhil,<br />
University of Science and Technology of China. <br />
No.96, JinZhai Road Baohe District, <br />
Hefei, Anhui, 230026, P.R.China. <br />
E-mail: <a href="hefengcs@gmail.com">hefengcs@gmail.com<br /></a></p>
[Last Update]：July 4, 2024 <br />

</td></tr></table>
<h2>About me</h2>
<p>Currently, I am pursuing a master's degree at the University of Science and Technology of China (USTC) in China. My main research interests lie in multimodal learning and makeup transfer. Prior to this, I graduated from the School of Computer Science at Yangtze University in June 2023.</p>
<h2>Research</h2>
<p>My research interests include: </p>
<ul>
<li><p>Deep Learning  </p>
</li>
<li><p>Vision-Language Models</p>
</li>
<li><p>Bearing Fault Diagnosis</p>
</li>
<li><p>Computer Vision</p>
</li>
</ul>
<h3>Current work</h3>
<ul>
<li><p>Makeup Transfer</p>
</li>
<li><p>Vision-Language Models</p>
</li>
</ul>
<h3>Under review</h3>
<ol>
  <li><p>Q. Chen , <b>F.He</b>, G.Wang, X.Bai, L. Cheng, X. Ning*, "Dual Guidance Enabled Fuzzy Inference for
    Enhanced Fine-Grained Recognition", IEEE Transactions on Fuzzy Systems(Major Revision)</p>
  
  <li><p>F. He, Q. Li*, About Diffusion Model in Makeup Transfer, Submitted to NIPS 2025</p>


</ol>
<h3>Recent publications </h3>
<ol>
  <li><p>X.Ning, <b>F.He</b>, X.Dong, W.Li*, "ICGNet: A Intensity-Controllable Generation Network based on the principle of homologous continuity for face attribute synthesis", Information Sciences(IF=8.1)[<a href="INS.pdf">pdf</a>].</p>

  <li><p>X.Ning, W.Tian, <b>F.He</b>, W.Li*, X.Bai*, "Hyper-sausage coverage function neuron model and learning algorithm for image classification ", Patten Recognition (IF = 7.5) [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322006951">pdf</a>]</p>
  </li> 
<li><p><b>F.He</b>, Q.Ye*, "A Bearing Fault Diagnosis Method Based on Wavelet Packet Transform and Convolutional Neural Network Optimized by Simulated Annealing Algorithm", Sensors (IF = 3.4) [<a href="pub/1.pdf">pdf</a>]</p>
</li>
<li><p><b>F.He</b>, Q.Ye*, S.Chen, Y.Zhou, "Evaluation of Higher Education System by TOPSIS Based on Entropy Weight Method", ICCAE2022 [<a href="pub/2.pdf">pdf</a>]</p>
  <li><p><b>F.He</b>, K.Bai, Y.Zong, Y.Zhou, Y.Jing, G.Wu*, C.Wang "Makeup Transfer: A review", IET Computer Vision  [<a href="pub/Makeup transfer A review.pdf">pdf</a>]</p>
  </li>
</li> 
<li><p>G.Wu, <b>F.He*</b>, Y.Zhou, Y.Jing,X.Ning,C.Wang "ACGAN : Age-Compensated Makeup Transfer Based on Homologous Continuity Generative Adversarial Network Model", IET Computer Vision [<a href="pub/ACGAN.pdf">pdf</a>]</p>
</li>
<li><p>G.Wu, X.Ning*, L.Hou*, <b>F.He</b>, H.Zhang, A.Shankar "Three-dimensional Softmax Mechanism Guided Bidirectional GRU Networks for Hyperspectral Remote Sensing Image Classification", Signal Processing [<a href="pub/SP.pdf">pdf</a>]</p>
</ol>
<p><b>Note</b>: * indicates the corresponding author.</p>
<p><a href="https://scholar.google.com.hk/citations?user=z_c2z70AAAAJ&hl=zh-CN">Full list of publications in Google Scholar</a>.</p>
<h3>Academic service</h3>
<p><b>Reviewer</b></p>
<ul>
<li><p>Concurrency and Computation: Practice and Experience</p>
</li>
<li><p>Connection Science</p>
</li>
<li><p>Displays</p>
</li>
<li><p>IET Computer VIsion</p>
</li>
<li><p>IET Image Processing</p>
</li>
  <li><p>The Visual Computer</p>
</li>
</ul>
<p><a href="https://www.webofscience.com/wos/author/record/2934781">More details in Publons</a></p>
<h2>Projects</h2>
<ol>
<li><p>An Adaptive Bearing Fault Diagnosis System, 09.2021-06.2023</p></li>
<ul>
<li><p>Develop an algorithm that can be used for bearing fault diagnosis</p>
</li>
<li><p>Use heuristics to tune hyperparameters </p>
</li>
<li><p>Using a combination of trust processing and deep learning to solve bearing fault diagnosis</p>
</li>
</ul>
</ol>
<h2>Education</h2>
<p>B.E., <a href="http://www.yangtzeu.edu.cn/">Yangtze University</a>, 06.2023</p>




<p>M.S., <a href="https://www.ustc.edu.cn/">University of Science and Technology of China(USTC)</a>, 06.2026</p>
</li>
</ul>

<h3>Competitions and awards</h3>
<ol>
</li>
<li><p>First prize , National College Student Computer Design Central and South Division, 6.2022</p> 
</li>
<li><p>Third prize , National College Student Computer Design Central and South Division, 6.2022</p> 
</li>
<li><p>Third prize , Blue Bridge Cup Hubei Division, 5.2022</p> 
</li> 
<li><p>Third prize , National College Student Computer Design Central and South Division, 5.2021</p>  
<li><p>Third prize , Hubei Province Division of National College Students Mathematical Modeling Competition, 9.2021</p>
</li>
<li><p>Second prize , National College Student Entrepreneurship Comprehensive Simulation Competition, 9.2021</p>
</li>
<li><p>Honorable Mention , ICM2021, 1.2021</p>
</li>
</ol>
<h2>Work experience</h2>
<ol>
<li><p>Research Assistant, High Speed Circuits and Neural Networks Laboratory, Institute of Semiconductors, Chinese Academy of Sciences, <a href="https://scholar.google.com.hk/citations?user=F3a4-tkAAAAJ&hl=zh-CN&oi=ao">Prof. Xin Ning</a>, 01.2022-10.2022</p></li>
<ul>
<li><p>Fund project declaration</p>
</li>
<li><p>Tracked, studied, reproduced, and improved up-to-date deep learning methods</p>
</li>
<li><p>Published papers on makeup transfer</p>
</li>
</ul>
<li><p>Research Assistant, University of Texas at San Antonio(UTSA), <a href="https://computationalurbanresilience.github.io/team.html">Prof. Wei Zhai</a>, 05.2022-10.2022</p></li>
<ul>
<li><p>Research on image generation.</p>
</li>
<li><p>For reproducing the latest papers, making improvements,and writing academic papers</p>
</li>
<li><p>Published papers on computer vision related to natural disasters.</p>
  </li>
</ul>
<li><p>Research Assistant, University of Science and Technology of China(USTC), <a href="http://staff.ustc.edu.cn/~harryjun/">Prof. Jun Yu</a>, now-9.2023</p></li>
<ul>
<li><p>Research on image generation.</p>
</li>
<li><p>For reproducing the latest papers, making improvements,and writing academic papers</p>
</li>
<li><p>Published papers on makeup transfer.</p>
</ol>
<p><br />

</td>
</tr>
</table>
</body>
</html>
